# 第3回任意課題

## 質問設計の観点と意図
AWSを活用した機械学習システムの構築を想定し設問を策定した。
設問設計の意図は以下の二点である。

第一に、本講義の前提条件として「PyTorchによるモデル学習経験およびHugging Faceを用いた事前学習済みモデル活用経験」が掲げられており、
受講者には機械学習に関する基礎知識が備わっていると想定される。一方で、AWSをはじめとするIaaSの運用経験は前提とされていないため、
受講者から関連質問が多く寄せられる可能性が高いと考えた。

第二に、AWSの公式ドキュメントは網羅性および正確性に優れており、関連文献の入手が容易であることから、設問の参考資料として適切であると判断した。

## 質問セット
回答は、ChatGPT o3（検索機能ON）により生成したものを記載している。
質問6は、2025年1月以降に発生した事象であり、ナレッジカットオフ以降であるためLLM単体で答えることができない。

### 1. すでに構築したクラウド環境を IaC に変換する機能はありますか？  
**回答**  
はい。AWS CloudFormation の *Resource Import* 機能では、既存リソースをテンプレートに記述してスタックへ取り込みます 。  
Terraform でも `terraform import` コマンドを使い、状態ファイルに既存リソースを登録できます 。  

---

### 2. 大量の機械学習トレーニングデータはどこに保管すべきですか？  
**回答**  
Amazon S3 が推奨です。オブジェクトを自動で冗長化し、11 ナイン (99.999999999 %) の耐久性を提供します。
データレイクや SageMaker とネイティブ統合され、ペタバイト級でもスケールを意識せずに利用できます 。  
S3 イベントで Lambda を呼び出せば、取込直後の前処理やメタデータ登録も自動化できます 。

---

### 3. SageMaker のトレーニングジョブが S3 にアクセスするには IAM ユーザーが必要ですか？  
**回答**  
IAM ユーザーは不要です。SageMaker には **IAM 実行ロール**を付与し、そのロールに `s3:*` など必要なポリシーをアタッチします 。  
ジョブ実行時、SageMaker はこのロールを引き受けて S3 や CloudWatch などのサービス API を呼び出します 。

---

### 4. トレーニング費用を抑える方法はありますか？  
**回答**  
Amazon SageMaker **Managed Spot Training** を有効にすると、オンデマンド比で最大 90 % のコスト削減が可能です 。  
Spot 中断に備えてチェックポイントを S3 に保存する仕組みがあり、再開時に自動で引き継げます 。  
学習時間よりコスト優先のワークロードで効果が高いベストプラクティスです 。

---

### 5. Notebook Instance と SageMaker Studio はどう使い分けるべきですか？  
**回答**  
Studio Classic ノートブックは起動が Notebook Instance より 5–10 倍速く、インスタンス種別もブラウザから即変更できます 。  
Notebook Instance はシングルユーザーで完全に分離した環境が欲しい場合や、従来の CLI/SDK 手順を重視するケースに向きます 。  
いずれも従量課金ですが、Studio はアイドル状態の EFS ストレージ料金、Instance は EC2 実行料金の最小化がポイントです 。

---

### 6. BedrockでDeepSeek-R1を使った場合、どのくらいの推論コストがかかりますか？
**回答**  
1,000 入力トークンあたりの料金は0.00135 USD、1,000 出力トークンあたりの料金は0.0054 USDです。
これは、他のオープンモデル（Llama 3.3など）に対して比較的高い料金となっています。

# 実験
## ベースのLLM（RAGなし）での回答
### 1. すでに構築したクラウド環境を IaC に変換する機能はありますか？
**回答**
はい、すでに構築したクラウド環境を Infrastructure as Code (IaC) に変換する機能はあります。例えば、AWS CloudFormation、Azure Resource Manager (ARM)、Google Cloud Deployment Manager などのクラウドプロバイダーが提供するツールや、third-party のソフトウェアとして、Cloudify、Terraform、Ansible などがあります。これらのツールを使用することで、既に構築されたクラウド環境を IaC に変換し、自動化されたインフラストラクチャーの管理を実現することができます。

---

### 2. 大量の機械学習トレーニングデータはどこに保管すべきですか？
**回答**
大量の機械学習トレーニングデータの保管方法は、企業や組織の規模、データの種類、セキュリティの要件などに依存します。以下は、一般的な保管方法の例です。

1. クラウドストレージ：AWS S3、Google Cloud Storage、Microsoft Azure Blob Storageなどのクラウドストレージサービスを使用することができます。これにより、データを安全に保管し、スケーラブルなアクセスを実現できます。
2. オンラインストレージ：Dropbox、Google Drive、Microsoft OneDriveなどのオンラインストレージサービスを使用することができます。これにより、データを簡単に共有し、どこからでもアクセスすることができます。
3. ハードウェアストレージ：企業のサーバーにハードウェアストレージを設置することができます。これにより、データを安全に保管し、高速にアクセスすることができます。
4. データセンター：企業のデータセンターにストレージを設置することができます。これにより、データを安全に保管し、高速にアクセスすることができます。

以上の

---

### 3. SageMaker のトレーニングジョブが S3 にアクセスするには IAM ユーザーが必要ですか？
**回答**
はい、SageMaker のトレーニングジョブが S3 にアクセスするには、IAM ユーザーが必要です。SageMaker は、IAM 認証を使用して S3 にアクセスし、データを読み書きするために、IAM ユーザーが必要です。SageMaker は、IAM ユーザーに紐付けたロールを使用して、S3 にアクセスし、データを読み書きします。

---

### 4. トレーニング費用を抑える方法はありますか？
**回答**
トレーニング費用を抑える方法はいくつかあります。まず、オンライントレーニングやMOOC（Massive Open Online Course）を活用することができます。これにより、コストを大幅に削減することができます。次に、自宅で実施するトレーニングや、同僚や友人と共同で実施するトレーニングも有効です。また、企業の内部トレーニングや、政府のサポートするトレーニングプログラムも活用することができます。最後に、トレーニングの内容を効率的に設計し、必要最小限度の時間で実施することも重要です。

---

### 5. Notebook Instance と SageMaker Studio はどう使い分けるべきですか？
**回答**
Notebook InstanceとSageMaker Studioは、AWS SageMakerの2つのサービスです。Notebook Instanceは、Jupyter NotebookやApache Zeppelinなどのnotebook環境を提供し、データサイエンティストや機械学習エンジニアがコードを実行するための環境を提供します。SageMaker Studioは、データサイエンティストや機械学習エンジニアが、機械学習モデルを開発、トレーニング、デプロイするための統合的なワークフローアプリケーションです。

Notebook Instanceは、個々のnotebook環境を提供し、各々のプロジェクトやタスクに特化した環境を提供します。SageMaker Studioは、複数のnotebook環境を統合的に管理し、プロジェクトの全体像を把握することができます。したがって、Notebook Instanceは、個々のnotebook環境を提供し、SageMaker Studioは、複数のnotebook環境を統合的に管理するためのサービスです。

---

### 6. BedrockでDeepSeek-R1を使った場合、どのくらいの推論コストがかかりますか？
**回答**
BedrockのDeepSeek-R1は、推論コストを最小化するために設計された深層学習ベースの推論エンジンです。具体的には、推論コストはBedrockのDeepSeek-R1の性能や設定によって異なります。

しかし、Bedrockの公式ドキュメントによると、DeepSeek-R1は、推論コストを平均して1-10ミリ秒程度と報告されています。ただし、実際の推論コストは、データサイズ、モデルサイズ、ハードウェアの性能など、多くの要因によって影響を受けるため、実際の推論コストは異なる可能性があります。

---

**評価結果**
| 評価番号 | スコア |
|:--------:|:------:|
| 1 | 2.00 |
| 2 | 0.00 |
| 3 | 0.00 |
| 4 | 0.00 |
| 5 | 0.00 |
| 6 | 0.00 |

## RAGありでの回答
RAGに与える事前情報は、AWSの公式ドキュメントから
質問に含まれるキーワードで検索したページのHTMLをパースして利用する。
パースには[HtmlRAG](https://github.com/plageon/HtmlRAG/tree/main)を用いる
参照： https://arxiv.org/abs/2411.02959v1


